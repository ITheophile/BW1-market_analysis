{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4  import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "from time import sleep\n",
    "from random import randint\n",
    "from warnings import warn\n",
    "from IPython.core.display import clear_output\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Needed\n",
    "name 1 webscraping    \n",
    "Price range, reflected in â‚¬ symbol ($= under $10. $$=11-30. $$$=31-60. $$$$= over $61) convert to euro.  1 webscraping    \n",
    "Rating  1 webscraping  \n",
    "Number of reviews  1 webscraping   \n",
    "Category (List)  1 webscraping \n",
    "Neighborhood   \n",
    "\n",
    "Location (any way to check proximity to popular places?)  2 webscraping  \n",
    "Opening and closing time  2 webscraping  \n",
    "Number of photos  2 webscraping  \n",
    "Website 2 webscraping    \n",
    "Features (List)  2 webscraping  \n",
    "  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Restaurants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = f\"https://www.yelp.com/search?find_desc=Restaurant&find_loc=Barcelona%2C+Spain&start=0\"\n",
    "response = requests.get(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  1 webscraping Hotels\n",
    "# Monitoring of the loop\n",
    "# start_time = time()\n",
    "# request = 0\n",
    "\n",
    "# # Dictionary for storing web content\n",
    "# soup_r = {}\n",
    "# for start_num in range(0, 240, 10):\n",
    "\n",
    "#     # Make a request\n",
    "#     url = f\"https://www.yelp.com/search?find_desc=Restaurant&find_loc=Barcelona%2C+Spain&start={start_num}\"\n",
    "#     response = requests.get(url)\n",
    "\n",
    "#     # Pause the loop\n",
    "#     sleep(randint(8,15))\n",
    "#     print(response)\n",
    "#     page = BeautifulSoup(response.content, 'html.parser')\n",
    "#     soup_r[start_num] = page\n",
    "\n",
    "\n",
    "#     # Monitor the requests\n",
    "#     request += 1\n",
    "#     elapsed_time = time() - start_time\n",
    "#     print('Request:{}; Frequency: {} requests/s'.format(request, request/elapsed_time))\n",
    "#     clear_output(wait = True)\n",
    "\n",
    "#     # Throw a warning if request wasn't successful\n",
    "#     if response.status_code != 200:\n",
    "#         warn('Request: {}; Status code: {}'.format(request, response.status_code))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to csv\n",
    "pd.DataFrame([soup_r]).to_csv('restaurant_soup.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Study case with first restaurant\n",
    "# link to more information about each business\n",
    "\n",
    "\n",
    "# accessing each business through its link in the name\n",
    "first_page = pd.read_csv('restaurant_soup').drop(columns='Unnamed: 0').squeeze()[0]\n",
    "first_page = BeautifulSoup(first_page, 'html.parser')\n",
    "first_resto = first_page.select('.css-1egxyvc .css-1m051bw')[0]\n",
    "link = first_resto['href']\n",
    "url = f'https://wwww.yelp.com{link}'\n",
    "response = requests.get(url)\n",
    "details = BeautifulSoup(response.content, 'html.parser')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# details about each business\n",
    "# request = 0\n",
    "# start_time = time()\n",
    "\n",
    "# soup_r2 = pd.DataFrame() \n",
    "# ser = pd.read_csv('restaurant_soup').drop(columns='Unnamed: 0').squeeze()\n",
    "# for row in ser:\n",
    "#     page = BeautifulSoup(row, 'html.parser')\n",
    "#     a_tags = page.select('.css-1egxyvc .css-1m051bw')\n",
    "#     for tag in a_tags:\n",
    "#         # print(tag)\n",
    "#         name = tag.text\n",
    "#         link = tag['href']\n",
    "#         url = f'https://wwww.yelp.com{link}'\n",
    "#         response = requests.get(url)\n",
    "\n",
    "#         # Pause the loop\n",
    "#         sleep(randint(8,15))\n",
    "#         print(response)\n",
    "#         page = BeautifulSoup(response.content, 'html.parser')\n",
    "#         soup_r2[name] = [page]\n",
    "\n",
    "#         # Monitor the requests\n",
    "#         request += 1\n",
    "#         elapsed_time = time() - start_time\n",
    "#         print('Request:{}; Frequency: {} requests/s'.format(request, request/elapsed_time))\n",
    "\n",
    "#         # Throw a warning if request wasn't successful\n",
    "#         if response.status_code != 200:\n",
    "#             warn('Request: {}; Status code: {}'.format(request, response.status_code))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Carrer de Mallorca, 236 ;08008 Barcelona ;Spain ;'"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example, extracting location\n",
    "location = ''\n",
    "for adress in soup_r2['Cerveseria Catalana'][0].select('address .raw__09f24__T4Ezm'):\n",
    "    location += adress.text + ';'\n",
    "\n",
    "\n",
    "location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "# names = []\n",
    "# ser = pd.read_csv('restaurant_soup').drop(columns='Unnamed: 0').squeeze()\n",
    "# for row in ser:\n",
    "#     soup = BeautifulSoup(row, 'html.parser')\n",
    "#     result = soup.select('.css-1egxyvc .css-1m051bw')\n",
    "#     for tag in result:\n",
    "#         names.append(tag.text)\n",
    "\n",
    "# pd.Series(names).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hotels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  1 webscraping Hotels\n",
    "# Monitoring of the loop\n",
    "# start_time = time()\n",
    "# request = 0\n",
    "\n",
    "# # Dictionary for storing web content\n",
    "# soup_h = {}\n",
    "# for start_num in range(0, 240, 10):\n",
    "\n",
    "#     # Make a request\n",
    "#     url = f\"https://www.yelp.com/search?find_desc=Hotels&find_loc=Barcelona%2C+Spain&start={start_num}\"\n",
    "#     response = requests.get(url)\n",
    "\n",
    "#     # Pause the loop\n",
    "#     sleep(randint(8,15))\n",
    "#     print(response)\n",
    "#     page = BeautifulSoup(response.content, 'html.parser')\n",
    "#     soup_h[start_num] = page\n",
    "\n",
    "\n",
    "#     # Monitor the requests\n",
    "#     request += 1\n",
    "#     elapsed_time = time() - start_time\n",
    "#     print('Request:{}; Frequency: {} requests/s'.format(request, request/elapsed_time))\n",
    "#     clear_output(wait = True)\n",
    "\n",
    "#     # Throw a warning if request wasn't successful\n",
    "#     if response.status_code != 200:\n",
    "#         warn('Request: {}; Status code: {}'.format(request, response.status_code))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save soup_h\n",
    "pd.DataFrame([soup_h]).to_csv('hotel_soup.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping from saved dataframe\n",
    "names = []\n",
    "ser = pd.read_csv('hotel_soup.csv').drop(columns='Unnamed: 0').squeeze()\n",
    "for row in ser:\n",
    "    soup = BeautifulSoup(row, 'html.parser')\n",
    "    result = soup.select('.css-1egxyvc .css-1m051bw')\n",
    "    for tag in result:\n",
    "        names.append(tag.text)\n",
    "\n",
    "# names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "# details about each business\n",
    "# request = 0\n",
    "# start_time = time()\n",
    "\n",
    "# soup_h2 = pd.DataFrame() \n",
    "# ser = pd.read_csv('hotel_soup.csv').drop(columns='Unnamed: 0').squeeze()\n",
    "# for row in ser [:13:-1]:\n",
    "#     page = BeautifulSoup(row, 'html.parser')\n",
    "#     a_tags = page.select('.css-1egxyvc .css-1m051bw')\n",
    "#     for tag in a_tags:\n",
    "#         # print(tag)\n",
    "#         name = tag.text\n",
    "#         link = tag['href']\n",
    "#         url = f'https://wwww.yelp.com{link}'\n",
    "#         response = requests.get(url)\n",
    "\n",
    "#         # Pause the loop\n",
    "#         sleep(randint(8,15))\n",
    "#         print(response)\n",
    "#         page = BeautifulSoup(response.content, 'html.parser')\n",
    "#         soup_h2[name] = [page]\n",
    "\n",
    "#         # Monitor the requests\n",
    "#         request += 1\n",
    "#         elapsed_time = time() - start_time\n",
    "#         print('Request:{}; Frequency: {} requests/s'.format(request, request/elapsed_time))\n",
    "\n",
    "#         # Throw a warning if request wasn't successful\n",
    "#         if response.status_code != 200:\n",
    "#             warn('Request: {}; Status code: {}'.format(request, response.status_code))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "# due to yelp's blocking, data scraped in two parts. Made a mistake during 1 part and appended hotel data to soup_r2 (restaurant)\n",
    "hotel_soup2 = pd.concat((soup_r2.iloc[:, 207:], soup_h2), axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save file\n",
    "hotel_soup2.to_csv('hotel_soup2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pubs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n",
      "Request:24; Frequency: 0.07382303659802342 requests/s\n"
     ]
    }
   ],
   "source": [
    "#  1 webscraping Hotels\n",
    "# Monitoring of the loop\n",
    "# start_time = time()\n",
    "# request = 0\n",
    "\n",
    "# # Dictionary for storing web content\n",
    "# soup_p = {}\n",
    "# for start_num in range(0, 240, 10):\n",
    "\n",
    "#     # Make a request\n",
    "#     url = f\"https://www.yelp.com/search?find_desc=Pubs&find_loc=Barcelona%2C+Spain&start={start_num}\"\n",
    "#     response = requests.get(url)\n",
    "\n",
    "#     # Pause the loop\n",
    "#     sleep(randint(8,15))\n",
    "#     print(response)\n",
    "#     page = BeautifulSoup(response.content, 'html.parser')\n",
    "#     soup_p[start_num] = page\n",
    "\n",
    "\n",
    "#     # Monitor the requests\n",
    "#     request += 1\n",
    "#     elapsed_time = time() - start_time\n",
    "#     print('Request:{}; Frequency: {} requests/s'.format(request, request/elapsed_time))\n",
    "#     clear_output(wait = True)\n",
    "\n",
    "#     # Throw a warning if request wasn't successful\n",
    "#     if response.status_code != 200:\n",
    "#         warn('Request: {}; Status code: {}'.format(request, response.status_code))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save soup_p\n",
    "pd.DataFrame([soup_p]).to_csv('pub_soup.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping from saved dataframe\n",
    "names = []\n",
    "ser = pd.read_csv('pub_soup.csv').drop(columns='Unnamed: 0').squeeze()\n",
    "for row in ser:\n",
    "    soup = BeautifulSoup(row, 'html.parser')\n",
    "    result = soup.select('.css-1egxyvc .css-1m051bw')\n",
    "    for tag in result:\n",
    "        names.append(tag.text)\n",
    "        # names.append(tag.text.split('.')[1].replace('\\xa0', ''))\n",
    "\n",
    "# names"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "db4d94f7962dcc818ea238f62a69636fa41bd28f5daf8a9f9234f6ae986cf5d4"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('strive')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
